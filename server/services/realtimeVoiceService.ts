import WebSocket from 'ws';
import OpenAI from 'openai';
import { fileManager } from './fileManager';

// OpenAI Realtime API GA version (not beta)
const REALTIME_MODEL = 'gpt-realtime';

interface RealtimeSession {
  id: string;
  conversationId: string;
  scenarioId: string;
  personaId: string;
  personaName: string; // Store persona name for first greeting
  userId: string;
  clientWs: WebSocket;
  openaiWs: WebSocket | null;
  isConnected: boolean;
  audioBuffer: Buffer[];
}

export class RealtimeVoiceService {
  private sessions: Map<string, RealtimeSession> = new Map();
  private openai: OpenAI | null = null;
  private isAvailable: boolean = false;

  constructor() {
    if (process.env.OPENAI_API_KEY) {
      this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
      this.isAvailable = true;
      console.log('âœ… OpenAI Realtime Voice Service initialized');
    } else {
      console.warn('âš ï¸  OPENAI_API_KEY not set - Realtime Voice features disabled');
    }
  }

  isServiceAvailable(): boolean {
    return this.isAvailable;
  }

  async createSession(
    sessionId: string,
    conversationId: string,
    scenarioId: string,
    personaId: string,
    userId: string,
    clientWs: WebSocket
  ): Promise<void> {
    if (!this.isAvailable || !this.openai) {
      throw new Error('OpenAI Realtime Voice Service is not available. Please configure OPENAI_API_KEY.');
    }

    console.log(`ğŸ™ï¸ Creating realtime voice session: ${sessionId}`);

    // Load scenario and persona data
    const scenarios = await fileManager.getAllScenarios();
    const scenarioObj = scenarios.find(s => s.id === scenarioId);
    if (!scenarioObj) {
      throw new Error(`Scenario not found: ${scenarioId}`);
    }

    const scenarioPersona: any = scenarioObj.personas.find((p: any) => p.id === personaId);
    if (!scenarioPersona) {
      throw new Error(`Persona not found: ${personaId}`);
    }

    // Load MBTI personality traits
    const mbtiType: string = scenarioPersona.personaRef?.replace('.json', '') || '';
    const mbtiPersona = mbtiType ? await fileManager.getPersonaByMBTI(mbtiType) : null;

    // Create system instructions combining scenario context and MBTI traits
    const systemInstructions = this.buildSystemInstructions(
      scenarioObj,
      scenarioPersona,
      mbtiPersona
    );

    // Create session object
    const session: RealtimeSession = {
      id: sessionId,
      conversationId,
      scenarioId,
      personaId,
      personaName: scenarioPersona.name, // Store persona name
      userId,
      clientWs,
      openaiWs: null,
      isConnected: false,
      audioBuffer: [],
    };

    this.sessions.set(sessionId, session);

    // Connect to OpenAI Realtime API
    await this.connectToOpenAI(session, systemInstructions);
  }

  private buildSystemInstructions(
    scenario: any,
    scenarioPersona: any,
    mbtiPersona: any
  ): string {
    const mbtiType = scenarioPersona.personaRef?.replace('.json', '') || 'UNKNOWN';
    
    const instructions = [
      `ë‹¹ì‹ ì€ "${scenarioPersona.name}"ì…ë‹ˆë‹¤.`,
      `ì—­í• : ${scenarioPersona.position} (${scenarioPersona.department})`,
      ``,
      `# ì‹œë‚˜ë¦¬ì˜¤ ë°°ê²½`,
      scenario.context?.situation || '',
      ``,
      `# í˜„ì¬ ìƒí™©`,
      scenarioPersona.currentSituation || '',
      ``,
      `# ë‹¹ì‹ ì˜ ì„±ê²© íŠ¹ì„± (MBTI: ${mbtiType})`,
      mbtiPersona?.communication_style || 'ê· í˜• ì¡íŒ ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼',
      ``,
      `# ëŒ€í™” íŒ¨í„´`,
      `- ì‹œì‘ ìŠ¤íƒ€ì¼: ${mbtiPersona?.communication_patterns?.opening_style || 'ìƒí™©ì— ë§ê²Œ ëŒ€í™” ì‹œì‘'}`,
      `- ì£¼ìš” í‘œí˜„: ${mbtiPersona?.communication_patterns?.key_phrases?.slice(0, 3).join(', ') || ''}`,
      ``,
      `# ë‹¹ì‹ ì˜ ê´€ì‹¬ì‚¬ì™€ ìš°ë ¤ì‚¬í•­`,
      ...(scenarioPersona.concerns || []).map((c: string) => `- ${c}`),
      ``,
      `# ëŒ€í™” ëª©í‘œ`,
      ...(mbtiPersona?.communication_patterns?.win_conditions || []).map((w: string) => `- ${w}`),
      ``,
      `# ì¤‘ìš” ì§€ì‹œì‚¬í•­`,
      `- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ëŒ€í™”í•˜ì„¸ìš”`,
      `- ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± í†¤ê³¼ ì–µì–‘ì„ ì‚¬ìš©í•˜ì„¸ìš”`,
      `- ë‹¹ì‹ ì˜ ê°ì • ìƒíƒœë¥¼ ìŒì„±ì— ë°˜ì˜í•˜ì„¸ìš”`,
      `- ì§§ê³  ê°„ê²°í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš” (1-3ë¬¸ì¥)`,
      `- ì‚¬ìš©ìì˜ ë§ì„ ê²½ì²­í•˜ê³  ì ì ˆíˆ ë°˜ì‘í•˜ì„¸ìš”`,
    ];

    return instructions.join('\n');
  }

  private async connectToOpenAI(
    session: RealtimeSession,
    systemInstructions: string
  ): Promise<void> {
    const url = 'wss://api.openai.com/v1/realtime?model=' + REALTIME_MODEL;
    
    const openaiWs = new WebSocket(url, {
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        // No OpenAI-Beta header needed for GA version
      },
    });

    session.openaiWs = openaiWs;

    openaiWs.on('open', () => {
      console.log(`âœ… OpenAI Realtime API connected for session: ${session.id}`);
      session.isConnected = true;

      // Configure session (GA API format)
      this.sendToOpenAI(session, {
        type: 'session.update',
        session: {
          type: 'realtime', // Required for GA version
          model: REALTIME_MODEL,
          instructions: systemInstructions,
          audio: {
            input: { 
              format: 'pcm16',
              transcription: {
                model: 'whisper-1',
              },
            },
            output: { 
              format: 'pcm16',
              voice: 'alloy' 
            },
          },
          turn_detection: null, // Disable server VAD, use manual control
          temperature: 0.8,
          max_response_output_tokens: 4096,
        },
      });

      // Notify client that session is ready
      this.sendToClient(session, {
        type: 'session.ready',
        sessionId: session.id,
      });
    });

    openaiWs.on('message', (data: WebSocket.Data) => {
      try {
        const event = JSON.parse(data.toString());
        this.handleOpenAIEvent(session, event);
      } catch (error) {
        console.error('Error parsing OpenAI message:', error);
      }
    });

    openaiWs.on('error', (error) => {
      console.error(`OpenAI WebSocket error for session ${session.id}:`, error);
      this.sendToClient(session, {
        type: 'error',
        error: 'OpenAI connection error',
      });
    });

    openaiWs.on('close', () => {
      console.log(`ğŸ”Œ OpenAI WebSocket closed for session: ${session.id}`);
      session.isConnected = false;
      
      // Notify client that OpenAI connection was closed
      this.sendToClient(session, {
        type: 'session.terminated',
        reason: 'OpenAI connection closed',
      });
      
      // Close client connection and clean up session
      if (session.clientWs && session.clientWs.readyState === WebSocket.OPEN) {
        session.clientWs.close(1000, 'OpenAI session ended');
      }
      
      this.sessions.delete(session.id);
      console.log(`â™»ï¸  Session cleaned up: ${session.id}`);
    });
  }

  private handleOpenAIEvent(session: RealtimeSession, event: any): void {
    console.log(`ğŸ“¨ OpenAI event: ${event.type}`);

    switch (event.type) {
      case 'session.created':
        this.sendToClient(session, {
          type: 'session.configured',
          ...event,
        });
        break;
      
      case 'session.updated':
        console.log('âœ… Session updated with our settings');
        console.log('ğŸ“‹ Updated session config:', JSON.stringify(event.session, null, 2));
        this.sendToClient(session, {
          type: 'session.configured',
          ...event,
        });
        // ì„¸ì…˜ì´ ì—…ë°ì´íŠ¸ë˜ë©´ AIê°€ ìë™ìœ¼ë¡œ ì²« ì¸ì‚¬ë¥¼ ì‹œì‘
        console.log('ğŸ¬ Triggering AI to start first greeting with full context...');
        
        // Create a contextual first message using stored persona name
        const firstMessage = `[ì‹œì‘] ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ë‹¹ì‹ ì€ ${session.personaName}ì…ë‹ˆë‹¤. ìƒí™©ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì¸ì‚¬í•˜ê³  ëŒ€í™”ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ ìŒì„±ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.`;
        
        console.log('ğŸ“ First message context:', firstMessage);
        
        // Add a conversation item first to prompt the AI
        this.sendToOpenAI(session, {
          type: 'conversation.item.create',
          item: {
            type: 'message',
            role: 'user',
            content: [
              {
                type: 'input_text',
                text: firstMessage,
              },
            ],
          },
        });
        
        // Then request audio response with explicit modalities
        this.sendToOpenAI(session, {
          type: 'response.create',
          response: {
            modalities: ['audio', 'text'],
            // instructions field is not supported in response.create
          },
        });
        break;

      case 'conversation.item.input_audio_transcription.completed':
        console.log(`ğŸ¤ User said: ${event.transcript}`);
        this.sendToClient(session, {
          type: 'user.transcription',
          transcript: event.transcript,
        });
        break;

      case 'response.output_audio.delta':
        // GA API: Forward audio chunks to client
        console.log('ğŸ”Š Audio delta received');
        this.sendToClient(session, {
          type: 'audio.delta',
          delta: event.delta,
        });
        break;

      case 'response.output_audio_transcript.delta':
        // GA API: Forward transcript to client
        console.log(`ğŸ¤– AI transcript: ${event.delta}`);
        this.sendToClient(session, {
          type: 'ai.transcription.delta',
          delta: event.delta,
        });
        break;

      case 'response.output_audio_transcript.done':
        // GA API: Complete transcript
        console.log(`âœ… AI full transcript: ${event.transcript}`);
        this.sendToClient(session, {
          type: 'ai.transcription.done',
          transcript: event.transcript,
        });
        break;

      case 'response.done':
        console.log(`âœ… Response complete`);
        console.log(`ğŸ“Š Response details:`, JSON.stringify(event.response, null, 2));
        this.sendToClient(session, {
          type: 'response.done',
        });
        break;

      case 'error':
        console.error(`âŒ OpenAI error:`, event.error);
        // Don't close session on empty buffer errors (recoverable)
        if (event.error?.code === 'input_audio_buffer_commit_empty') {
          console.log('âš ï¸  Empty audio buffer - ignoring');
          return;
        }
        this.sendToClient(session, {
          type: 'error',
          error: event.error,
        });
        break;

      default:
        // Forward other events as-is for debugging
        this.sendToClient(session, event);
    }
  }

  handleClientMessage(sessionId: string, message: any): void {
    const session = this.sessions.get(sessionId);
    if (!session) {
      console.error(`Session not found: ${sessionId}`);
      return;
    }

    if (!session.isConnected || !session.openaiWs) {
      console.error(`OpenAI not connected for session: ${sessionId}`);
      return;
    }

    // Forward client messages to OpenAI
    switch (message.type) {
      case 'input_audio_buffer.append':
        // Client sending audio data
        this.sendToOpenAI(session, {
          type: 'input_audio_buffer.append',
          audio: message.audio,
        });
        break;

      case 'input_audio_buffer.commit':
        // Client finished speaking
        this.sendToOpenAI(session, {
          type: 'input_audio_buffer.commit',
        });
        break;

      case 'response.create':
        // Client requesting a response
        this.sendToOpenAI(session, {
          type: 'response.create',
        });
        break;

      case 'conversation.item.create':
        // Client sending a text message
        this.sendToOpenAI(session, {
          type: 'conversation.item.create',
          item: message.item,
        });
        break;

      default:
        console.log(`Unknown client message type: ${message.type}`);
    }
  }

  private sendToOpenAI(session: RealtimeSession, message: any): void {
    if (session.openaiWs && session.isConnected) {
      session.openaiWs.send(JSON.stringify(message));
    }
  }

  private sendToClient(session: RealtimeSession, message: any): void {
    if (session.clientWs && session.clientWs.readyState === WebSocket.OPEN) {
      session.clientWs.send(JSON.stringify(message));
    }
  }

  closeSession(sessionId: string): void {
    const session = this.sessions.get(sessionId);
    if (session) {
      console.log(`ğŸ”š Closing realtime voice session: ${sessionId}`);
      
      if (session.openaiWs) {
        session.openaiWs.close();
      }
      
      this.sessions.delete(sessionId);
    }
  }

  getActiveSessionCount(): number {
    return this.sessions.size;
  }
}

export const realtimeVoiceService = new RealtimeVoiceService();
